{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN + LSTM.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCMFgi81_dU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHjtE06L_rxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,LSTM\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIIaUOgJANqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [[[(i+j)/100] for i in range(5)] for j in range(100)]\n",
        "target = [(i+5)/100 for i in range(100)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxAxYB1iBg9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "012f9149-9c4c-45c9-e920-2854cbcc7bc2"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.0], [0.01], [0.02], [0.03], [0.04]], [[0.01], [0.02], [0.03], [0.04], [0.05]], [[0.02], [0.03], [0.04], [0.05], [0.06]], [[0.03], [0.04], [0.05], [0.06], [0.07]], [[0.04], [0.05], [0.06], [0.07], [0.08]], [[0.05], [0.06], [0.07], [0.08], [0.09]], [[0.06], [0.07], [0.08], [0.09], [0.1]], [[0.07], [0.08], [0.09], [0.1], [0.11]], [[0.08], [0.09], [0.1], [0.11], [0.12]], [[0.09], [0.1], [0.11], [0.12], [0.13]], [[0.1], [0.11], [0.12], [0.13], [0.14]], [[0.11], [0.12], [0.13], [0.14], [0.15]], [[0.12], [0.13], [0.14], [0.15], [0.16]], [[0.13], [0.14], [0.15], [0.16], [0.17]], [[0.14], [0.15], [0.16], [0.17], [0.18]], [[0.15], [0.16], [0.17], [0.18], [0.19]], [[0.16], [0.17], [0.18], [0.19], [0.2]], [[0.17], [0.18], [0.19], [0.2], [0.21]], [[0.18], [0.19], [0.2], [0.21], [0.22]], [[0.19], [0.2], [0.21], [0.22], [0.23]], [[0.2], [0.21], [0.22], [0.23], [0.24]], [[0.21], [0.22], [0.23], [0.24], [0.25]], [[0.22], [0.23], [0.24], [0.25], [0.26]], [[0.23], [0.24], [0.25], [0.26], [0.27]], [[0.24], [0.25], [0.26], [0.27], [0.28]], [[0.25], [0.26], [0.27], [0.28], [0.29]], [[0.26], [0.27], [0.28], [0.29], [0.3]], [[0.27], [0.28], [0.29], [0.3], [0.31]], [[0.28], [0.29], [0.3], [0.31], [0.32]], [[0.29], [0.3], [0.31], [0.32], [0.33]], [[0.3], [0.31], [0.32], [0.33], [0.34]], [[0.31], [0.32], [0.33], [0.34], [0.35]], [[0.32], [0.33], [0.34], [0.35], [0.36]], [[0.33], [0.34], [0.35], [0.36], [0.37]], [[0.34], [0.35], [0.36], [0.37], [0.38]], [[0.35], [0.36], [0.37], [0.38], [0.39]], [[0.36], [0.37], [0.38], [0.39], [0.4]], [[0.37], [0.38], [0.39], [0.4], [0.41]], [[0.38], [0.39], [0.4], [0.41], [0.42]], [[0.39], [0.4], [0.41], [0.42], [0.43]], [[0.4], [0.41], [0.42], [0.43], [0.44]], [[0.41], [0.42], [0.43], [0.44], [0.45]], [[0.42], [0.43], [0.44], [0.45], [0.46]], [[0.43], [0.44], [0.45], [0.46], [0.47]], [[0.44], [0.45], [0.46], [0.47], [0.48]], [[0.45], [0.46], [0.47], [0.48], [0.49]], [[0.46], [0.47], [0.48], [0.49], [0.5]], [[0.47], [0.48], [0.49], [0.5], [0.51]], [[0.48], [0.49], [0.5], [0.51], [0.52]], [[0.49], [0.5], [0.51], [0.52], [0.53]], [[0.5], [0.51], [0.52], [0.53], [0.54]], [[0.51], [0.52], [0.53], [0.54], [0.55]], [[0.52], [0.53], [0.54], [0.55], [0.56]], [[0.53], [0.54], [0.55], [0.56], [0.57]], [[0.54], [0.55], [0.56], [0.57], [0.58]], [[0.55], [0.56], [0.57], [0.58], [0.59]], [[0.56], [0.57], [0.58], [0.59], [0.6]], [[0.57], [0.58], [0.59], [0.6], [0.61]], [[0.58], [0.59], [0.6], [0.61], [0.62]], [[0.59], [0.6], [0.61], [0.62], [0.63]], [[0.6], [0.61], [0.62], [0.63], [0.64]], [[0.61], [0.62], [0.63], [0.64], [0.65]], [[0.62], [0.63], [0.64], [0.65], [0.66]], [[0.63], [0.64], [0.65], [0.66], [0.67]], [[0.64], [0.65], [0.66], [0.67], [0.68]], [[0.65], [0.66], [0.67], [0.68], [0.69]], [[0.66], [0.67], [0.68], [0.69], [0.7]], [[0.67], [0.68], [0.69], [0.7], [0.71]], [[0.68], [0.69], [0.7], [0.71], [0.72]], [[0.69], [0.7], [0.71], [0.72], [0.73]], [[0.7], [0.71], [0.72], [0.73], [0.74]], [[0.71], [0.72], [0.73], [0.74], [0.75]], [[0.72], [0.73], [0.74], [0.75], [0.76]], [[0.73], [0.74], [0.75], [0.76], [0.77]], [[0.74], [0.75], [0.76], [0.77], [0.78]], [[0.75], [0.76], [0.77], [0.78], [0.79]], [[0.76], [0.77], [0.78], [0.79], [0.8]], [[0.77], [0.78], [0.79], [0.8], [0.81]], [[0.78], [0.79], [0.8], [0.81], [0.82]], [[0.79], [0.8], [0.81], [0.82], [0.83]], [[0.8], [0.81], [0.82], [0.83], [0.84]], [[0.81], [0.82], [0.83], [0.84], [0.85]], [[0.82], [0.83], [0.84], [0.85], [0.86]], [[0.83], [0.84], [0.85], [0.86], [0.87]], [[0.84], [0.85], [0.86], [0.87], [0.88]], [[0.85], [0.86], [0.87], [0.88], [0.89]], [[0.86], [0.87], [0.88], [0.89], [0.9]], [[0.87], [0.88], [0.89], [0.9], [0.91]], [[0.88], [0.89], [0.9], [0.91], [0.92]], [[0.89], [0.9], [0.91], [0.92], [0.93]], [[0.9], [0.91], [0.92], [0.93], [0.94]], [[0.91], [0.92], [0.93], [0.94], [0.95]], [[0.92], [0.93], [0.94], [0.95], [0.96]], [[0.93], [0.94], [0.95], [0.96], [0.97]], [[0.94], [0.95], [0.96], [0.97], [0.98]], [[0.95], [0.96], [0.97], [0.98], [0.99]], [[0.96], [0.97], [0.98], [0.99], [1.0]], [[0.97], [0.98], [0.99], [1.0], [1.01]], [[0.98], [0.99], [1.0], [1.01], [1.02]], [[0.99], [1.0], [1.01], [1.02], [1.03]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc_8KjX7BiY0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8618de3e-dfb1-429a-f0e6-92d9a57173a8"
      },
      "source": [
        "print(target)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At_ZqDvaBxXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array(data , dtype = float)\n",
        "target = np.array(target , dtype = float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yt2L21rB107",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae5256ef-845f-4966-f7a4-9936477289ea"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhaMqhIbCVzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a31ef2c9-1102-46ad-8e74-ef961c5419f6"
      },
      "source": [
        "target.shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DL42AsnCXtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train , x_test ,y_train ,y_test = train_test_split(data ,target ,test_size = 0.2 , random_state= 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrXU7oG-DJxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-ZUwfQlEA_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ab2e3b08-9e31-455e-ce22-171b3fad924e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 5, 1)              12        \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 1)                 12        \n",
            "=================================================================\n",
            "Total params: 24\n",
            "Trainable params: 24\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgFTeMj9EVte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13634
        },
        "outputId": "89a47890-aa9e-482c-d7b8-b236d98cafb6"
      },
      "source": [
        "history = model.fit(x_train , y_train , epochs = 400 , validation_data = (x_test , y_test))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/400\n",
            "80/80 [==============================] - 3s 33ms/step - loss: 0.5045 - acc: 0.0000e+00 - val_loss: 0.4715 - val_acc: 0.0000e+00\n",
            "Epoch 2/400\n",
            "80/80 [==============================] - 0s 397us/step - loss: 0.5013 - acc: 0.0000e+00 - val_loss: 0.4682 - val_acc: 0.0000e+00\n",
            "Epoch 3/400\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.4978 - acc: 0.0000e+00 - val_loss: 0.4648 - val_acc: 0.0000e+00\n",
            "Epoch 4/400\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.4943 - acc: 0.0000e+00 - val_loss: 0.4613 - val_acc: 0.0000e+00\n",
            "Epoch 5/400\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.4908 - acc: 0.0000e+00 - val_loss: 0.4577 - val_acc: 0.0000e+00\n",
            "Epoch 6/400\n",
            "80/80 [==============================] - 0s 378us/step - loss: 0.4871 - acc: 0.0000e+00 - val_loss: 0.4541 - val_acc: 0.0000e+00\n",
            "Epoch 7/400\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.4834 - acc: 0.0000e+00 - val_loss: 0.4504 - val_acc: 0.0000e+00\n",
            "Epoch 8/400\n",
            "80/80 [==============================] - 0s 391us/step - loss: 0.4796 - acc: 0.0000e+00 - val_loss: 0.4466 - val_acc: 0.0000e+00\n",
            "Epoch 9/400\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.4758 - acc: 0.0000e+00 - val_loss: 0.4428 - val_acc: 0.0000e+00\n",
            "Epoch 10/400\n",
            "80/80 [==============================] - 0s 389us/step - loss: 0.4719 - acc: 0.0000e+00 - val_loss: 0.4389 - val_acc: 0.0000e+00\n",
            "Epoch 11/400\n",
            "80/80 [==============================] - 0s 462us/step - loss: 0.4679 - acc: 0.0000e+00 - val_loss: 0.4350 - val_acc: 0.0000e+00\n",
            "Epoch 12/400\n",
            "80/80 [==============================] - 0s 419us/step - loss: 0.4639 - acc: 0.0000e+00 - val_loss: 0.4310 - val_acc: 0.0000e+00\n",
            "Epoch 13/400\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.4598 - acc: 0.0000e+00 - val_loss: 0.4269 - val_acc: 0.0000e+00\n",
            "Epoch 14/400\n",
            "80/80 [==============================] - 0s 446us/step - loss: 0.4556 - acc: 0.0000e+00 - val_loss: 0.4227 - val_acc: 0.0000e+00\n",
            "Epoch 15/400\n",
            "80/80 [==============================] - 0s 412us/step - loss: 0.4513 - acc: 0.0000e+00 - val_loss: 0.4185 - val_acc: 0.0000e+00\n",
            "Epoch 16/400\n",
            "80/80 [==============================] - 0s 404us/step - loss: 0.4470 - acc: 0.0000e+00 - val_loss: 0.4142 - val_acc: 0.0000e+00\n",
            "Epoch 17/400\n",
            "80/80 [==============================] - 0s 438us/step - loss: 0.4427 - acc: 0.0000e+00 - val_loss: 0.4098 - val_acc: 0.0000e+00\n",
            "Epoch 18/400\n",
            "80/80 [==============================] - 0s 398us/step - loss: 0.4383 - acc: 0.0000e+00 - val_loss: 0.4054 - val_acc: 0.0000e+00\n",
            "Epoch 19/400\n",
            "80/80 [==============================] - 0s 365us/step - loss: 0.4339 - acc: 0.0000e+00 - val_loss: 0.4009 - val_acc: 0.0000e+00\n",
            "Epoch 20/400\n",
            "80/80 [==============================] - 0s 420us/step - loss: 0.4294 - acc: 0.0000e+00 - val_loss: 0.3964 - val_acc: 0.0000e+00\n",
            "Epoch 21/400\n",
            "80/80 [==============================] - 0s 407us/step - loss: 0.4249 - acc: 0.0000e+00 - val_loss: 0.3919 - val_acc: 0.0000e+00\n",
            "Epoch 22/400\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.4205 - acc: 0.0000e+00 - val_loss: 0.3876 - val_acc: 0.0000e+00\n",
            "Epoch 23/400\n",
            "80/80 [==============================] - 0s 469us/step - loss: 0.4160 - acc: 0.0000e+00 - val_loss: 0.3833 - val_acc: 0.0000e+00\n",
            "Epoch 24/400\n",
            "80/80 [==============================] - 0s 440us/step - loss: 0.4114 - acc: 0.0000e+00 - val_loss: 0.3789 - val_acc: 0.0000e+00\n",
            "Epoch 25/400\n",
            "80/80 [==============================] - 0s 381us/step - loss: 0.4068 - acc: 0.0000e+00 - val_loss: 0.3745 - val_acc: 0.0000e+00\n",
            "Epoch 26/400\n",
            "80/80 [==============================] - 0s 419us/step - loss: 0.4023 - acc: 0.0000e+00 - val_loss: 0.3700 - val_acc: 0.0000e+00\n",
            "Epoch 27/400\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.3978 - acc: 0.0000e+00 - val_loss: 0.3655 - val_acc: 0.0000e+00\n",
            "Epoch 28/400\n",
            "80/80 [==============================] - 0s 451us/step - loss: 0.3933 - acc: 0.0000e+00 - val_loss: 0.3611 - val_acc: 0.0000e+00\n",
            "Epoch 29/400\n",
            "80/80 [==============================] - 0s 433us/step - loss: 0.3887 - acc: 0.0000e+00 - val_loss: 0.3566 - val_acc: 0.0000e+00\n",
            "Epoch 30/400\n",
            "80/80 [==============================] - 0s 440us/step - loss: 0.3844 - acc: 0.0000e+00 - val_loss: 0.3521 - val_acc: 0.0000e+00\n",
            "Epoch 31/400\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.3801 - acc: 0.0000e+00 - val_loss: 0.3478 - val_acc: 0.0000e+00\n",
            "Epoch 32/400\n",
            "80/80 [==============================] - 0s 430us/step - loss: 0.3756 - acc: 0.0000e+00 - val_loss: 0.3436 - val_acc: 0.0000e+00\n",
            "Epoch 33/400\n",
            "80/80 [==============================] - 0s 428us/step - loss: 0.3711 - acc: 0.0000e+00 - val_loss: 0.3399 - val_acc: 0.0000e+00\n",
            "Epoch 34/400\n",
            "80/80 [==============================] - 0s 418us/step - loss: 0.3667 - acc: 0.0000e+00 - val_loss: 0.3361 - val_acc: 0.0000e+00\n",
            "Epoch 35/400\n",
            "80/80 [==============================] - 0s 417us/step - loss: 0.3622 - acc: 0.0000e+00 - val_loss: 0.3324 - val_acc: 0.0000e+00\n",
            "Epoch 36/400\n",
            "80/80 [==============================] - 0s 428us/step - loss: 0.3578 - acc: 0.0000e+00 - val_loss: 0.3286 - val_acc: 0.0000e+00\n",
            "Epoch 37/400\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.3535 - acc: 0.0000e+00 - val_loss: 0.3249 - val_acc: 0.0000e+00\n",
            "Epoch 38/400\n",
            "80/80 [==============================] - 0s 428us/step - loss: 0.3493 - acc: 0.0000e+00 - val_loss: 0.3212 - val_acc: 0.0000e+00\n",
            "Epoch 39/400\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.3453 - acc: 0.0000e+00 - val_loss: 0.3174 - val_acc: 0.0000e+00\n",
            "Epoch 40/400\n",
            "80/80 [==============================] - 0s 386us/step - loss: 0.3411 - acc: 0.0000e+00 - val_loss: 0.3137 - val_acc: 0.0000e+00\n",
            "Epoch 41/400\n",
            "80/80 [==============================] - 0s 361us/step - loss: 0.3371 - acc: 0.0000e+00 - val_loss: 0.3103 - val_acc: 0.0000e+00\n",
            "Epoch 42/400\n",
            "80/80 [==============================] - 0s 410us/step - loss: 0.3333 - acc: 0.0000e+00 - val_loss: 0.3071 - val_acc: 0.0000e+00\n",
            "Epoch 43/400\n",
            "80/80 [==============================] - 0s 414us/step - loss: 0.3296 - acc: 0.0000e+00 - val_loss: 0.3040 - val_acc: 0.0000e+00\n",
            "Epoch 44/400\n",
            "80/80 [==============================] - 0s 426us/step - loss: 0.3255 - acc: 0.0000e+00 - val_loss: 0.3010 - val_acc: 0.0000e+00\n",
            "Epoch 45/400\n",
            "80/80 [==============================] - 0s 438us/step - loss: 0.3220 - acc: 0.0000e+00 - val_loss: 0.2979 - val_acc: 0.0000e+00\n",
            "Epoch 46/400\n",
            "80/80 [==============================] - 0s 361us/step - loss: 0.3186 - acc: 0.0000e+00 - val_loss: 0.2952 - val_acc: 0.0000e+00\n",
            "Epoch 47/400\n",
            "80/80 [==============================] - 0s 402us/step - loss: 0.3151 - acc: 0.0000e+00 - val_loss: 0.2927 - val_acc: 0.0000e+00\n",
            "Epoch 48/400\n",
            "80/80 [==============================] - 0s 424us/step - loss: 0.3116 - acc: 0.0000e+00 - val_loss: 0.2901 - val_acc: 0.0000e+00\n",
            "Epoch 49/400\n",
            "80/80 [==============================] - 0s 424us/step - loss: 0.3083 - acc: 0.0000e+00 - val_loss: 0.2877 - val_acc: 0.0000e+00\n",
            "Epoch 50/400\n",
            "80/80 [==============================] - 0s 432us/step - loss: 0.3051 - acc: 0.0000e+00 - val_loss: 0.2852 - val_acc: 0.0000e+00\n",
            "Epoch 51/400\n",
            "80/80 [==============================] - 0s 422us/step - loss: 0.3019 - acc: 0.0000e+00 - val_loss: 0.2828 - val_acc: 0.0000e+00\n",
            "Epoch 52/400\n",
            "80/80 [==============================] - 0s 387us/step - loss: 0.2991 - acc: 0.0000e+00 - val_loss: 0.2803 - val_acc: 0.0000e+00\n",
            "Epoch 53/400\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.2959 - acc: 0.0000e+00 - val_loss: 0.2780 - val_acc: 0.0000e+00\n",
            "Epoch 54/400\n",
            "80/80 [==============================] - 0s 418us/step - loss: 0.2932 - acc: 0.0000e+00 - val_loss: 0.2757 - val_acc: 0.0000e+00\n",
            "Epoch 55/400\n",
            "80/80 [==============================] - 0s 412us/step - loss: 0.2905 - acc: 0.0000e+00 - val_loss: 0.2735 - val_acc: 0.0000e+00\n",
            "Epoch 56/400\n",
            "80/80 [==============================] - 0s 447us/step - loss: 0.2880 - acc: 0.0000e+00 - val_loss: 0.2713 - val_acc: 0.0000e+00\n",
            "Epoch 57/400\n",
            "80/80 [==============================] - 0s 476us/step - loss: 0.2856 - acc: 0.0000e+00 - val_loss: 0.2695 - val_acc: 0.0000e+00\n",
            "Epoch 58/400\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.2831 - acc: 0.0000e+00 - val_loss: 0.2678 - val_acc: 0.0000e+00\n",
            "Epoch 59/400\n",
            "80/80 [==============================] - 0s 392us/step - loss: 0.2807 - acc: 0.0000e+00 - val_loss: 0.2662 - val_acc: 0.0000e+00\n",
            "Epoch 60/400\n",
            "80/80 [==============================] - 0s 402us/step - loss: 0.2786 - acc: 0.0000e+00 - val_loss: 0.2645 - val_acc: 0.0000e+00\n",
            "Epoch 61/400\n",
            "80/80 [==============================] - 0s 413us/step - loss: 0.2763 - acc: 0.0000e+00 - val_loss: 0.2632 - val_acc: 0.0000e+00\n",
            "Epoch 62/400\n",
            "80/80 [==============================] - 0s 448us/step - loss: 0.2742 - acc: 0.0000e+00 - val_loss: 0.2619 - val_acc: 0.0000e+00\n",
            "Epoch 63/400\n",
            "80/80 [==============================] - 0s 425us/step - loss: 0.2719 - acc: 0.0000e+00 - val_loss: 0.2607 - val_acc: 0.0000e+00\n",
            "Epoch 64/400\n",
            "80/80 [==============================] - 0s 379us/step - loss: 0.2698 - acc: 0.0000e+00 - val_loss: 0.2595 - val_acc: 0.0000e+00\n",
            "Epoch 65/400\n",
            "80/80 [==============================] - 0s 367us/step - loss: 0.2678 - acc: 0.0000e+00 - val_loss: 0.2584 - val_acc: 0.0000e+00\n",
            "Epoch 66/400\n",
            "80/80 [==============================] - 0s 427us/step - loss: 0.2660 - acc: 0.0000e+00 - val_loss: 0.2576 - val_acc: 0.0000e+00\n",
            "Epoch 67/400\n",
            "80/80 [==============================] - 0s 408us/step - loss: 0.2640 - acc: 0.0000e+00 - val_loss: 0.2568 - val_acc: 0.0000e+00\n",
            "Epoch 68/400\n",
            "80/80 [==============================] - 0s 395us/step - loss: 0.2620 - acc: 0.0000e+00 - val_loss: 0.2560 - val_acc: 0.0000e+00\n",
            "Epoch 69/400\n",
            "80/80 [==============================] - 0s 462us/step - loss: 0.2602 - acc: 0.0000e+00 - val_loss: 0.2552 - val_acc: 0.0000e+00\n",
            "Epoch 70/400\n",
            "80/80 [==============================] - 0s 395us/step - loss: 0.2586 - acc: 0.0000e+00 - val_loss: 0.2544 - val_acc: 0.0000e+00\n",
            "Epoch 71/400\n",
            "80/80 [==============================] - 0s 381us/step - loss: 0.2569 - acc: 0.0000e+00 - val_loss: 0.2536 - val_acc: 0.0000e+00\n",
            "Epoch 72/400\n",
            "80/80 [==============================] - 0s 446us/step - loss: 0.2553 - acc: 0.0000e+00 - val_loss: 0.2528 - val_acc: 0.0000e+00\n",
            "Epoch 73/400\n",
            "80/80 [==============================] - 0s 439us/step - loss: 0.2536 - acc: 0.0000e+00 - val_loss: 0.2520 - val_acc: 0.0000e+00\n",
            "Epoch 74/400\n",
            "80/80 [==============================] - 0s 404us/step - loss: 0.2523 - acc: 0.0000e+00 - val_loss: 0.2513 - val_acc: 0.0000e+00\n",
            "Epoch 75/400\n",
            "80/80 [==============================] - 0s 418us/step - loss: 0.2507 - acc: 0.0000e+00 - val_loss: 0.2506 - val_acc: 0.0000e+00\n",
            "Epoch 76/400\n",
            "80/80 [==============================] - 0s 334us/step - loss: 0.2494 - acc: 0.0000e+00 - val_loss: 0.2501 - val_acc: 0.0000e+00\n",
            "Epoch 77/400\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.2481 - acc: 0.0000e+00 - val_loss: 0.2496 - val_acc: 0.0000e+00\n",
            "Epoch 78/400\n",
            "80/80 [==============================] - 0s 412us/step - loss: 0.2466 - acc: 0.0000e+00 - val_loss: 0.2491 - val_acc: 0.0000e+00\n",
            "Epoch 79/400\n",
            "80/80 [==============================] - 0s 428us/step - loss: 0.2452 - acc: 0.0000e+00 - val_loss: 0.2486 - val_acc: 0.0000e+00\n",
            "Epoch 80/400\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.2441 - acc: 0.0000e+00 - val_loss: 0.2480 - val_acc: 0.0000e+00\n",
            "Epoch 81/400\n",
            "80/80 [==============================] - 0s 416us/step - loss: 0.2427 - acc: 0.0000e+00 - val_loss: 0.2475 - val_acc: 0.0000e+00\n",
            "Epoch 82/400\n",
            "80/80 [==============================] - 0s 420us/step - loss: 0.2415 - acc: 0.0000e+00 - val_loss: 0.2470 - val_acc: 0.0000e+00\n",
            "Epoch 83/400\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.2402 - acc: 0.0000e+00 - val_loss: 0.2464 - val_acc: 0.0000e+00\n",
            "Epoch 84/400\n",
            "80/80 [==============================] - 0s 432us/step - loss: 0.2391 - acc: 0.0000e+00 - val_loss: 0.2459 - val_acc: 0.0000e+00\n",
            "Epoch 85/400\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.2379 - acc: 0.0000e+00 - val_loss: 0.2453 - val_acc: 0.0000e+00\n",
            "Epoch 86/400\n",
            "80/80 [==============================] - 0s 388us/step - loss: 0.2368 - acc: 0.0000e+00 - val_loss: 0.2450 - val_acc: 0.0000e+00\n",
            "Epoch 87/400\n",
            "80/80 [==============================] - 0s 416us/step - loss: 0.2356 - acc: 0.0000e+00 - val_loss: 0.2446 - val_acc: 0.0000e+00\n",
            "Epoch 88/400\n",
            "80/80 [==============================] - 0s 400us/step - loss: 0.2344 - acc: 0.0000e+00 - val_loss: 0.2442 - val_acc: 0.0000e+00\n",
            "Epoch 89/400\n",
            "80/80 [==============================] - 0s 390us/step - loss: 0.2334 - acc: 0.0000e+00 - val_loss: 0.2439 - val_acc: 0.0000e+00\n",
            "Epoch 90/400\n",
            "80/80 [==============================] - 0s 436us/step - loss: 0.2322 - acc: 0.0000e+00 - val_loss: 0.2435 - val_acc: 0.0000e+00\n",
            "Epoch 91/400\n",
            "80/80 [==============================] - 0s 428us/step - loss: 0.2310 - acc: 0.0000e+00 - val_loss: 0.2431 - val_acc: 0.0000e+00\n",
            "Epoch 92/400\n",
            "80/80 [==============================] - 0s 441us/step - loss: 0.2300 - acc: 0.0000e+00 - val_loss: 0.2426 - val_acc: 0.0000e+00\n",
            "Epoch 93/400\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.2289 - acc: 0.0000e+00 - val_loss: 0.2422 - val_acc: 0.0000e+00\n",
            "Epoch 94/400\n",
            "80/80 [==============================] - 0s 420us/step - loss: 0.2278 - acc: 0.0000e+00 - val_loss: 0.2416 - val_acc: 0.0000e+00\n",
            "Epoch 95/400\n",
            "80/80 [==============================] - 0s 377us/step - loss: 0.2267 - acc: 0.0000e+00 - val_loss: 0.2411 - val_acc: 0.0000e+00\n",
            "Epoch 96/400\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.2257 - acc: 0.0000e+00 - val_loss: 0.2405 - val_acc: 0.0000e+00\n",
            "Epoch 97/400\n",
            "80/80 [==============================] - 0s 396us/step - loss: 0.2247 - acc: 0.0000e+00 - val_loss: 0.2400 - val_acc: 0.0000e+00\n",
            "Epoch 98/400\n",
            "80/80 [==============================] - 0s 455us/step - loss: 0.2236 - acc: 0.0000e+00 - val_loss: 0.2394 - val_acc: 0.0000e+00\n",
            "Epoch 99/400\n",
            "80/80 [==============================] - 0s 436us/step - loss: 0.2226 - acc: 0.0000e+00 - val_loss: 0.2388 - val_acc: 0.0000e+00\n",
            "Epoch 100/400\n",
            "80/80 [==============================] - 0s 427us/step - loss: 0.2216 - acc: 0.0000e+00 - val_loss: 0.2381 - val_acc: 0.0000e+00\n",
            "Epoch 101/400\n",
            "80/80 [==============================] - 0s 388us/step - loss: 0.2205 - acc: 0.0000e+00 - val_loss: 0.2374 - val_acc: 0.0000e+00\n",
            "Epoch 102/400\n",
            "80/80 [==============================] - 0s 417us/step - loss: 0.2195 - acc: 0.0000e+00 - val_loss: 0.2367 - val_acc: 0.0000e+00\n",
            "Epoch 103/400\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.2185 - acc: 0.0000e+00 - val_loss: 0.2359 - val_acc: 0.0000e+00\n",
            "Epoch 104/400\n",
            "80/80 [==============================] - 0s 395us/step - loss: 0.2175 - acc: 0.0000e+00 - val_loss: 0.2351 - val_acc: 0.0000e+00\n",
            "Epoch 105/400\n",
            "80/80 [==============================] - 0s 367us/step - loss: 0.2164 - acc: 0.0000e+00 - val_loss: 0.2342 - val_acc: 0.0000e+00\n",
            "Epoch 106/400\n",
            "80/80 [==============================] - 0s 392us/step - loss: 0.2154 - acc: 0.0000e+00 - val_loss: 0.2333 - val_acc: 0.0000e+00\n",
            "Epoch 107/400\n",
            "80/80 [==============================] - 0s 415us/step - loss: 0.2143 - acc: 0.0000e+00 - val_loss: 0.2324 - val_acc: 0.0000e+00\n",
            "Epoch 108/400\n",
            "80/80 [==============================] - 0s 422us/step - loss: 0.2133 - acc: 0.0000e+00 - val_loss: 0.2314 - val_acc: 0.0000e+00\n",
            "Epoch 109/400\n",
            "80/80 [==============================] - 0s 450us/step - loss: 0.2122 - acc: 0.0000e+00 - val_loss: 0.2304 - val_acc: 0.0000e+00\n",
            "Epoch 110/400\n",
            "80/80 [==============================] - 0s 637us/step - loss: 0.2111 - acc: 0.0000e+00 - val_loss: 0.2294 - val_acc: 0.0000e+00\n",
            "Epoch 111/400\n",
            "80/80 [==============================] - 0s 539us/step - loss: 0.2100 - acc: 0.0000e+00 - val_loss: 0.2284 - val_acc: 0.0000e+00\n",
            "Epoch 112/400\n",
            "80/80 [==============================] - 0s 404us/step - loss: 0.2088 - acc: 0.0000e+00 - val_loss: 0.2273 - val_acc: 0.0000e+00\n",
            "Epoch 113/400\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.2076 - acc: 0.0000e+00 - val_loss: 0.2261 - val_acc: 0.0000e+00\n",
            "Epoch 114/400\n",
            "80/80 [==============================] - 0s 417us/step - loss: 0.2065 - acc: 0.0000e+00 - val_loss: 0.2250 - val_acc: 0.0000e+00\n",
            "Epoch 115/400\n",
            "80/80 [==============================] - 0s 407us/step - loss: 0.2054 - acc: 0.0000e+00 - val_loss: 0.2237 - val_acc: 0.0000e+00\n",
            "Epoch 116/400\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.2041 - acc: 0.0000e+00 - val_loss: 0.2224 - val_acc: 0.0000e+00\n",
            "Epoch 117/400\n",
            "80/80 [==============================] - 0s 427us/step - loss: 0.2029 - acc: 0.0000e+00 - val_loss: 0.2211 - val_acc: 0.0000e+00\n",
            "Epoch 118/400\n",
            "80/80 [==============================] - 0s 476us/step - loss: 0.2016 - acc: 0.0000e+00 - val_loss: 0.2197 - val_acc: 0.0000e+00\n",
            "Epoch 119/400\n",
            "80/80 [==============================] - 0s 375us/step - loss: 0.2004 - acc: 0.0000e+00 - val_loss: 0.2182 - val_acc: 0.0000e+00\n",
            "Epoch 120/400\n",
            "80/80 [==============================] - 0s 433us/step - loss: 0.1990 - acc: 0.0000e+00 - val_loss: 0.2168 - val_acc: 0.0000e+00\n",
            "Epoch 121/400\n",
            "80/80 [==============================] - 0s 415us/step - loss: 0.1977 - acc: 0.0000e+00 - val_loss: 0.2153 - val_acc: 0.0500\n",
            "Epoch 122/400\n",
            "80/80 [==============================] - 0s 373us/step - loss: 0.1963 - acc: 0.0000e+00 - val_loss: 0.2137 - val_acc: 0.0500\n",
            "Epoch 123/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.1949 - acc: 0.0000e+00 - val_loss: 0.2120 - val_acc: 0.0500\n",
            "Epoch 124/400\n",
            "80/80 [==============================] - 0s 444us/step - loss: 0.1935 - acc: 0.0000e+00 - val_loss: 0.2103 - val_acc: 0.0500\n",
            "Epoch 125/400\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.1921 - acc: 0.0000e+00 - val_loss: 0.2086 - val_acc: 0.0500\n",
            "Epoch 126/400\n",
            "80/80 [==============================] - 0s 393us/step - loss: 0.1905 - acc: 0.0000e+00 - val_loss: 0.2068 - val_acc: 0.0500\n",
            "Epoch 127/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.1890 - acc: 0.0000e+00 - val_loss: 0.2049 - val_acc: 0.0500\n",
            "Epoch 128/400\n",
            "80/80 [==============================] - 0s 368us/step - loss: 0.1874 - acc: 0.0000e+00 - val_loss: 0.2030 - val_acc: 0.0500\n",
            "Epoch 129/400\n",
            "80/80 [==============================] - 0s 373us/step - loss: 0.1858 - acc: 0.0000e+00 - val_loss: 0.2011 - val_acc: 0.0500\n",
            "Epoch 130/400\n",
            "80/80 [==============================] - 0s 417us/step - loss: 0.1841 - acc: 0.0000e+00 - val_loss: 0.1990 - val_acc: 0.0500\n",
            "Epoch 131/400\n",
            "80/80 [==============================] - 0s 406us/step - loss: 0.1826 - acc: 0.0000e+00 - val_loss: 0.1967 - val_acc: 0.0500\n",
            "Epoch 132/400\n",
            "80/80 [==============================] - 0s 483us/step - loss: 0.1808 - acc: 0.0000e+00 - val_loss: 0.1944 - val_acc: 0.0500\n",
            "Epoch 133/400\n",
            "80/80 [==============================] - 0s 419us/step - loss: 0.1790 - acc: 0.0000e+00 - val_loss: 0.1923 - val_acc: 0.0500\n",
            "Epoch 134/400\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.1773 - acc: 0.0000e+00 - val_loss: 0.1900 - val_acc: 0.0500\n",
            "Epoch 135/400\n",
            "80/80 [==============================] - 0s 378us/step - loss: 0.1756 - acc: 0.0000e+00 - val_loss: 0.1877 - val_acc: 0.0500\n",
            "Epoch 136/400\n",
            "80/80 [==============================] - 0s 500us/step - loss: 0.1737 - acc: 0.0000e+00 - val_loss: 0.1855 - val_acc: 0.0500\n",
            "Epoch 137/400\n",
            "80/80 [==============================] - 0s 422us/step - loss: 0.1718 - acc: 0.0000e+00 - val_loss: 0.1830 - val_acc: 0.0500\n",
            "Epoch 138/400\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.1700 - acc: 0.0000e+00 - val_loss: 0.1804 - val_acc: 0.0500\n",
            "Epoch 139/400\n",
            "80/80 [==============================] - 0s 453us/step - loss: 0.1680 - acc: 0.0000e+00 - val_loss: 0.1780 - val_acc: 0.0500\n",
            "Epoch 140/400\n",
            "80/80 [==============================] - 0s 395us/step - loss: 0.1662 - acc: 0.0000e+00 - val_loss: 0.1753 - val_acc: 0.0500\n",
            "Epoch 141/400\n",
            "80/80 [==============================] - 0s 405us/step - loss: 0.1641 - acc: 0.0000e+00 - val_loss: 0.1728 - val_acc: 0.0500\n",
            "Epoch 142/400\n",
            "80/80 [==============================] - 0s 424us/step - loss: 0.1621 - acc: 0.0000e+00 - val_loss: 0.1702 - val_acc: 0.0500\n",
            "Epoch 143/400\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.1601 - acc: 0.0000e+00 - val_loss: 0.1675 - val_acc: 0.0500\n",
            "Epoch 144/400\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.1580 - acc: 0.0000e+00 - val_loss: 0.1649 - val_acc: 0.0500\n",
            "Epoch 145/400\n",
            "80/80 [==============================] - 0s 419us/step - loss: 0.1559 - acc: 0.0000e+00 - val_loss: 0.1623 - val_acc: 0.0500\n",
            "Epoch 146/400\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.1538 - acc: 0.0000e+00 - val_loss: 0.1597 - val_acc: 0.0500\n",
            "Epoch 147/400\n",
            "80/80 [==============================] - 0s 388us/step - loss: 0.1516 - acc: 0.0000e+00 - val_loss: 0.1571 - val_acc: 0.0500\n",
            "Epoch 148/400\n",
            "80/80 [==============================] - 0s 401us/step - loss: 0.1494 - acc: 0.0000e+00 - val_loss: 0.1542 - val_acc: 0.0500\n",
            "Epoch 149/400\n",
            "80/80 [==============================] - 0s 399us/step - loss: 0.1472 - acc: 0.0000e+00 - val_loss: 0.1511 - val_acc: 0.0500\n",
            "Epoch 150/400\n",
            "80/80 [==============================] - 0s 457us/step - loss: 0.1448 - acc: 0.0000e+00 - val_loss: 0.1482 - val_acc: 0.0500\n",
            "Epoch 151/400\n",
            "80/80 [==============================] - 0s 417us/step - loss: 0.1425 - acc: 0.0000e+00 - val_loss: 0.1452 - val_acc: 0.0500\n",
            "Epoch 152/400\n",
            "80/80 [==============================] - 0s 379us/step - loss: 0.1402 - acc: 0.0000e+00 - val_loss: 0.1423 - val_acc: 0.0500\n",
            "Epoch 153/400\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.1377 - acc: 0.0000e+00 - val_loss: 0.1393 - val_acc: 0.0500\n",
            "Epoch 154/400\n",
            "80/80 [==============================] - 0s 414us/step - loss: 0.1353 - acc: 0.0000e+00 - val_loss: 0.1362 - val_acc: 0.0500\n",
            "Epoch 155/400\n",
            "80/80 [==============================] - 0s 426us/step - loss: 0.1329 - acc: 0.0000e+00 - val_loss: 0.1345 - val_acc: 0.0500\n",
            "Epoch 156/400\n",
            "80/80 [==============================] - 0s 411us/step - loss: 0.1314 - acc: 0.0000e+00 - val_loss: 0.1335 - val_acc: 0.0500\n",
            "Epoch 157/400\n",
            "80/80 [==============================] - 0s 425us/step - loss: 0.1298 - acc: 0.0000e+00 - val_loss: 0.1325 - val_acc: 0.0500\n",
            "Epoch 158/400\n",
            "80/80 [==============================] - 0s 458us/step - loss: 0.1279 - acc: 0.0000e+00 - val_loss: 0.1315 - val_acc: 0.0500\n",
            "Epoch 159/400\n",
            "80/80 [==============================] - 0s 381us/step - loss: 0.1264 - acc: 0.0000e+00 - val_loss: 0.1305 - val_acc: 0.0500\n",
            "Epoch 160/400\n",
            "80/80 [==============================] - 0s 373us/step - loss: 0.1249 - acc: 0.0000e+00 - val_loss: 0.1297 - val_acc: 0.0500\n",
            "Epoch 161/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.1238 - acc: 0.0000e+00 - val_loss: 0.1289 - val_acc: 0.0500\n",
            "Epoch 162/400\n",
            "80/80 [==============================] - 0s 354us/step - loss: 0.1228 - acc: 0.0000e+00 - val_loss: 0.1280 - val_acc: 0.0500\n",
            "Epoch 163/400\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.1218 - acc: 0.0000e+00 - val_loss: 0.1273 - val_acc: 0.0500\n",
            "Epoch 164/400\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.1209 - acc: 0.0000e+00 - val_loss: 0.1264 - val_acc: 0.0500\n",
            "Epoch 165/400\n",
            "80/80 [==============================] - 0s 443us/step - loss: 0.1200 - acc: 0.0000e+00 - val_loss: 0.1255 - val_acc: 0.0500\n",
            "Epoch 166/400\n",
            "80/80 [==============================] - 0s 454us/step - loss: 0.1192 - acc: 0.0000e+00 - val_loss: 0.1247 - val_acc: 0.0500\n",
            "Epoch 167/400\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.1184 - acc: 0.0000e+00 - val_loss: 0.1241 - val_acc: 0.0500\n",
            "Epoch 168/400\n",
            "80/80 [==============================] - 0s 414us/step - loss: 0.1175 - acc: 0.0000e+00 - val_loss: 0.1234 - val_acc: 0.0500\n",
            "Epoch 169/400\n",
            "80/80 [==============================] - 0s 388us/step - loss: 0.1167 - acc: 0.0000e+00 - val_loss: 0.1226 - val_acc: 0.0500\n",
            "Epoch 170/400\n",
            "80/80 [==============================] - 0s 419us/step - loss: 0.1160 - acc: 0.0000e+00 - val_loss: 0.1218 - val_acc: 0.0500\n",
            "Epoch 171/400\n",
            "80/80 [==============================] - 0s 419us/step - loss: 0.1151 - acc: 0.0000e+00 - val_loss: 0.1210 - val_acc: 0.0500\n",
            "Epoch 172/400\n",
            "80/80 [==============================] - 0s 459us/step - loss: 0.1143 - acc: 0.0000e+00 - val_loss: 0.1202 - val_acc: 0.0500\n",
            "Epoch 173/400\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.1135 - acc: 0.0000e+00 - val_loss: 0.1194 - val_acc: 0.0500\n",
            "Epoch 174/400\n",
            "80/80 [==============================] - 0s 426us/step - loss: 0.1128 - acc: 0.0000e+00 - val_loss: 0.1186 - val_acc: 0.0500\n",
            "Epoch 175/400\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.1121 - acc: 0.0000e+00 - val_loss: 0.1178 - val_acc: 0.0500\n",
            "Epoch 176/400\n",
            "80/80 [==============================] - 0s 464us/step - loss: 0.1114 - acc: 0.0000e+00 - val_loss: 0.1169 - val_acc: 0.0500\n",
            "Epoch 177/400\n",
            "80/80 [==============================] - 0s 423us/step - loss: 0.1106 - acc: 0.0000e+00 - val_loss: 0.1162 - val_acc: 0.0500\n",
            "Epoch 178/400\n",
            "80/80 [==============================] - 0s 418us/step - loss: 0.1099 - acc: 0.0000e+00 - val_loss: 0.1154 - val_acc: 0.0500\n",
            "Epoch 179/400\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.1092 - acc: 0.0000e+00 - val_loss: 0.1147 - val_acc: 0.0500\n",
            "Epoch 180/400\n",
            "80/80 [==============================] - 0s 410us/step - loss: 0.1085 - acc: 0.0000e+00 - val_loss: 0.1139 - val_acc: 0.0500\n",
            "Epoch 181/400\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.1078 - acc: 0.0000e+00 - val_loss: 0.1131 - val_acc: 0.0500\n",
            "Epoch 182/400\n",
            "80/80 [==============================] - 0s 410us/step - loss: 0.1071 - acc: 0.0000e+00 - val_loss: 0.1123 - val_acc: 0.0500\n",
            "Epoch 183/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.1064 - acc: 0.0000e+00 - val_loss: 0.1114 - val_acc: 0.0500\n",
            "Epoch 184/400\n",
            "80/80 [==============================] - 0s 434us/step - loss: 0.1058 - acc: 0.0000e+00 - val_loss: 0.1106 - val_acc: 0.0500\n",
            "Epoch 185/400\n",
            "80/80 [==============================] - 0s 389us/step - loss: 0.1051 - acc: 0.0000e+00 - val_loss: 0.1099 - val_acc: 0.0500\n",
            "Epoch 186/400\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.1045 - acc: 0.0000e+00 - val_loss: 0.1092 - val_acc: 0.0500\n",
            "Epoch 187/400\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.1038 - acc: 0.0000e+00 - val_loss: 0.1084 - val_acc: 0.0500\n",
            "Epoch 188/400\n",
            "80/80 [==============================] - 0s 411us/step - loss: 0.1032 - acc: 0.0000e+00 - val_loss: 0.1077 - val_acc: 0.0500\n",
            "Epoch 189/400\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.1025 - acc: 0.0000e+00 - val_loss: 0.1070 - val_acc: 0.0500\n",
            "Epoch 190/400\n",
            "80/80 [==============================] - 0s 462us/step - loss: 0.1019 - acc: 0.0000e+00 - val_loss: 0.1063 - val_acc: 0.0500\n",
            "Epoch 191/400\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.1013 - acc: 0.0000e+00 - val_loss: 0.1056 - val_acc: 0.0500\n",
            "Epoch 192/400\n",
            "80/80 [==============================] - 0s 401us/step - loss: 0.1006 - acc: 0.0000e+00 - val_loss: 0.1049 - val_acc: 0.0500\n",
            "Epoch 193/400\n",
            "80/80 [==============================] - 0s 389us/step - loss: 0.1000 - acc: 0.0000e+00 - val_loss: 0.1042 - val_acc: 0.0500\n",
            "Epoch 194/400\n",
            "80/80 [==============================] - 0s 420us/step - loss: 0.0994 - acc: 0.0000e+00 - val_loss: 0.1035 - val_acc: 0.0500\n",
            "Epoch 195/400\n",
            "80/80 [==============================] - 0s 407us/step - loss: 0.0988 - acc: 0.0000e+00 - val_loss: 0.1028 - val_acc: 0.0500\n",
            "Epoch 196/400\n",
            "80/80 [==============================] - 0s 416us/step - loss: 0.0981 - acc: 0.0000e+00 - val_loss: 0.1022 - val_acc: 0.0500\n",
            "Epoch 197/400\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.0976 - acc: 0.0000e+00 - val_loss: 0.1015 - val_acc: 0.0500\n",
            "Epoch 198/400\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.0969 - acc: 0.0000e+00 - val_loss: 0.1007 - val_acc: 0.0500\n",
            "Epoch 199/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.0963 - acc: 0.0000e+00 - val_loss: 0.1001 - val_acc: 0.0500\n",
            "Epoch 200/400\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.0957 - acc: 0.0000e+00 - val_loss: 0.0994 - val_acc: 0.0500\n",
            "Epoch 201/400\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.0952 - acc: 0.0000e+00 - val_loss: 0.0987 - val_acc: 0.0500\n",
            "Epoch 202/400\n",
            "80/80 [==============================] - 0s 423us/step - loss: 0.0945 - acc: 0.0000e+00 - val_loss: 0.0981 - val_acc: 0.0500\n",
            "Epoch 203/400\n",
            "80/80 [==============================] - 0s 446us/step - loss: 0.0940 - acc: 0.0000e+00 - val_loss: 0.0974 - val_acc: 0.0500\n",
            "Epoch 204/400\n",
            "80/80 [==============================] - 0s 381us/step - loss: 0.0934 - acc: 0.0000e+00 - val_loss: 0.0967 - val_acc: 0.0500\n",
            "Epoch 205/400\n",
            "80/80 [==============================] - 0s 404us/step - loss: 0.0929 - acc: 0.0000e+00 - val_loss: 0.0961 - val_acc: 0.0500\n",
            "Epoch 206/400\n",
            "80/80 [==============================] - 0s 393us/step - loss: 0.0922 - acc: 0.0000e+00 - val_loss: 0.0956 - val_acc: 0.0500\n",
            "Epoch 207/400\n",
            "80/80 [==============================] - 0s 405us/step - loss: 0.0916 - acc: 0.0000e+00 - val_loss: 0.0951 - val_acc: 0.0500\n",
            "Epoch 208/400\n",
            "80/80 [==============================] - 0s 419us/step - loss: 0.0910 - acc: 0.0000e+00 - val_loss: 0.0947 - val_acc: 0.0500\n",
            "Epoch 209/400\n",
            "80/80 [==============================] - 0s 400us/step - loss: 0.0905 - acc: 0.0000e+00 - val_loss: 0.0943 - val_acc: 0.0500\n",
            "Epoch 210/400\n",
            "80/80 [==============================] - 0s 430us/step - loss: 0.0899 - acc: 0.0000e+00 - val_loss: 0.0938 - val_acc: 0.0500\n",
            "Epoch 211/400\n",
            "80/80 [==============================] - 0s 424us/step - loss: 0.0893 - acc: 0.0000e+00 - val_loss: 0.0931 - val_acc: 0.0500\n",
            "Epoch 212/400\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.0887 - acc: 0.0000e+00 - val_loss: 0.0923 - val_acc: 0.0500\n",
            "Epoch 213/400\n",
            "80/80 [==============================] - 0s 387us/step - loss: 0.0881 - acc: 0.0000e+00 - val_loss: 0.0915 - val_acc: 0.0500\n",
            "Epoch 214/400\n",
            "80/80 [==============================] - 0s 393us/step - loss: 0.0876 - acc: 0.0000e+00 - val_loss: 0.0908 - val_acc: 0.0500\n",
            "Epoch 215/400\n",
            "80/80 [==============================] - 0s 364us/step - loss: 0.0870 - acc: 0.0000e+00 - val_loss: 0.0903 - val_acc: 0.0500\n",
            "Epoch 216/400\n",
            "80/80 [==============================] - 0s 441us/step - loss: 0.0864 - acc: 0.0000e+00 - val_loss: 0.0896 - val_acc: 0.0500\n",
            "Epoch 217/400\n",
            "80/80 [==============================] - 0s 373us/step - loss: 0.0859 - acc: 0.0000e+00 - val_loss: 0.0891 - val_acc: 0.0500\n",
            "Epoch 218/400\n",
            "80/80 [==============================] - 0s 433us/step - loss: 0.0853 - acc: 0.0000e+00 - val_loss: 0.0884 - val_acc: 0.0500\n",
            "Epoch 219/400\n",
            "80/80 [==============================] - 0s 408us/step - loss: 0.0848 - acc: 0.0000e+00 - val_loss: 0.0881 - val_acc: 0.0500\n",
            "Epoch 220/400\n",
            "80/80 [==============================] - 0s 358us/step - loss: 0.0842 - acc: 0.0000e+00 - val_loss: 0.0877 - val_acc: 0.0500\n",
            "Epoch 221/400\n",
            "80/80 [==============================] - 0s 407us/step - loss: 0.0836 - acc: 0.0000e+00 - val_loss: 0.0870 - val_acc: 0.0500\n",
            "Epoch 222/400\n",
            "80/80 [==============================] - 0s 440us/step - loss: 0.0831 - acc: 0.0000e+00 - val_loss: 0.0864 - val_acc: 0.0500\n",
            "Epoch 223/400\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.0826 - acc: 0.0000e+00 - val_loss: 0.0859 - val_acc: 0.0500\n",
            "Epoch 224/400\n",
            "80/80 [==============================] - 0s 446us/step - loss: 0.0820 - acc: 0.0000e+00 - val_loss: 0.0855 - val_acc: 0.0500\n",
            "Epoch 225/400\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.0815 - acc: 0.0000e+00 - val_loss: 0.0854 - val_acc: 0.0500\n",
            "Epoch 226/400\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.0810 - acc: 0.0000e+00 - val_loss: 0.0850 - val_acc: 0.0500\n",
            "Epoch 227/400\n",
            "80/80 [==============================] - 0s 403us/step - loss: 0.0805 - acc: 0.0000e+00 - val_loss: 0.0844 - val_acc: 0.0500\n",
            "Epoch 228/400\n",
            "80/80 [==============================] - 0s 411us/step - loss: 0.0799 - acc: 0.0000e+00 - val_loss: 0.0835 - val_acc: 0.0500\n",
            "Epoch 229/400\n",
            "80/80 [==============================] - 0s 428us/step - loss: 0.0794 - acc: 0.0000e+00 - val_loss: 0.0827 - val_acc: 0.0500\n",
            "Epoch 230/400\n",
            "80/80 [==============================] - 0s 382us/step - loss: 0.0788 - acc: 0.0000e+00 - val_loss: 0.0821 - val_acc: 0.0500\n",
            "Epoch 231/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.0783 - acc: 0.0000e+00 - val_loss: 0.0816 - val_acc: 0.0500\n",
            "Epoch 232/400\n",
            "80/80 [==============================] - 0s 408us/step - loss: 0.0778 - acc: 0.0000e+00 - val_loss: 0.0810 - val_acc: 0.0500\n",
            "Epoch 233/400\n",
            "80/80 [==============================] - 0s 478us/step - loss: 0.0772 - acc: 0.0000e+00 - val_loss: 0.0806 - val_acc: 0.0500\n",
            "Epoch 234/400\n",
            "80/80 [==============================] - 0s 420us/step - loss: 0.0767 - acc: 0.0000e+00 - val_loss: 0.0800 - val_acc: 0.0500\n",
            "Epoch 235/400\n",
            "80/80 [==============================] - 0s 440us/step - loss: 0.0762 - acc: 0.0000e+00 - val_loss: 0.0795 - val_acc: 0.0500\n",
            "Epoch 236/400\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0757 - acc: 0.0000e+00 - val_loss: 0.0792 - val_acc: 0.0500\n",
            "Epoch 237/400\n",
            "80/80 [==============================] - 0s 420us/step - loss: 0.0751 - acc: 0.0000e+00 - val_loss: 0.0786 - val_acc: 0.0500\n",
            "Epoch 238/400\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.0745 - acc: 0.0000e+00 - val_loss: 0.0782 - val_acc: 0.0500\n",
            "Epoch 239/400\n",
            "80/80 [==============================] - 0s 427us/step - loss: 0.0741 - acc: 0.0000e+00 - val_loss: 0.0778 - val_acc: 0.0500\n",
            "Epoch 240/400\n",
            "80/80 [==============================] - 0s 414us/step - loss: 0.0734 - acc: 0.0000e+00 - val_loss: 0.0776 - val_acc: 0.0500\n",
            "Epoch 241/400\n",
            "80/80 [==============================] - 0s 427us/step - loss: 0.0730 - acc: 0.0000e+00 - val_loss: 0.0773 - val_acc: 0.0500\n",
            "Epoch 242/400\n",
            "80/80 [==============================] - 0s 402us/step - loss: 0.0725 - acc: 0.0000e+00 - val_loss: 0.0768 - val_acc: 0.0500\n",
            "Epoch 243/400\n",
            "80/80 [==============================] - 0s 412us/step - loss: 0.0719 - acc: 0.0000e+00 - val_loss: 0.0764 - val_acc: 0.0500\n",
            "Epoch 244/400\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.0713 - acc: 0.0000e+00 - val_loss: 0.0759 - val_acc: 0.0500\n",
            "Epoch 245/400\n",
            "80/80 [==============================] - 0s 431us/step - loss: 0.0708 - acc: 0.0000e+00 - val_loss: 0.0754 - val_acc: 0.0500\n",
            "Epoch 246/400\n",
            "80/80 [==============================] - 0s 394us/step - loss: 0.0704 - acc: 0.0000e+00 - val_loss: 0.0750 - val_acc: 0.0500\n",
            "Epoch 247/400\n",
            "80/80 [==============================] - 0s 447us/step - loss: 0.0698 - acc: 0.0000e+00 - val_loss: 0.0747 - val_acc: 0.0500\n",
            "Epoch 248/400\n",
            "80/80 [==============================] - 0s 358us/step - loss: 0.0694 - acc: 0.0000e+00 - val_loss: 0.0745 - val_acc: 0.0500\n",
            "Epoch 249/400\n",
            "80/80 [==============================] - 0s 453us/step - loss: 0.0689 - acc: 0.0000e+00 - val_loss: 0.0742 - val_acc: 0.0500\n",
            "Epoch 250/400\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.0684 - acc: 0.0000e+00 - val_loss: 0.0740 - val_acc: 0.0500\n",
            "Epoch 251/400\n",
            "80/80 [==============================] - 0s 408us/step - loss: 0.0679 - acc: 0.0000e+00 - val_loss: 0.0740 - val_acc: 0.0500\n",
            "Epoch 252/400\n",
            "80/80 [==============================] - 0s 365us/step - loss: 0.0674 - acc: 0.0000e+00 - val_loss: 0.0737 - val_acc: 0.0500\n",
            "Epoch 253/400\n",
            "80/80 [==============================] - 0s 409us/step - loss: 0.0670 - acc: 0.0000e+00 - val_loss: 0.0732 - val_acc: 0.0500\n",
            "Epoch 254/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.0666 - acc: 0.0000e+00 - val_loss: 0.0725 - val_acc: 0.0500\n",
            "Epoch 255/400\n",
            "80/80 [==============================] - 0s 405us/step - loss: 0.0660 - acc: 0.0000e+00 - val_loss: 0.0720 - val_acc: 0.0500\n",
            "Epoch 256/400\n",
            "80/80 [==============================] - 0s 445us/step - loss: 0.0656 - acc: 0.0000e+00 - val_loss: 0.0717 - val_acc: 0.0500\n",
            "Epoch 257/400\n",
            "80/80 [==============================] - 0s 446us/step - loss: 0.0651 - acc: 0.0000e+00 - val_loss: 0.0713 - val_acc: 0.0500\n",
            "Epoch 258/400\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.0647 - acc: 0.0000e+00 - val_loss: 0.0710 - val_acc: 0.0500\n",
            "Epoch 259/400\n",
            "80/80 [==============================] - 0s 422us/step - loss: 0.0642 - acc: 0.0000e+00 - val_loss: 0.0710 - val_acc: 0.0500\n",
            "Epoch 260/400\n",
            "80/80 [==============================] - 0s 412us/step - loss: 0.0638 - acc: 0.0000e+00 - val_loss: 0.0708 - val_acc: 0.0500\n",
            "Epoch 261/400\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.0633 - acc: 0.0000e+00 - val_loss: 0.0706 - val_acc: 0.0500\n",
            "Epoch 262/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.0629 - acc: 0.0000e+00 - val_loss: 0.0703 - val_acc: 0.0500\n",
            "Epoch 263/400\n",
            "80/80 [==============================] - 0s 395us/step - loss: 0.0625 - acc: 0.0000e+00 - val_loss: 0.0703 - val_acc: 0.0500\n",
            "Epoch 264/400\n",
            "80/80 [==============================] - 0s 399us/step - loss: 0.0621 - acc: 0.0000e+00 - val_loss: 0.0699 - val_acc: 0.0500\n",
            "Epoch 265/400\n",
            "80/80 [==============================] - 0s 440us/step - loss: 0.0616 - acc: 0.0000e+00 - val_loss: 0.0692 - val_acc: 0.0500\n",
            "Epoch 266/400\n",
            "80/80 [==============================] - 0s 451us/step - loss: 0.0612 - acc: 0.0000e+00 - val_loss: 0.0682 - val_acc: 0.0500\n",
            "Epoch 267/400\n",
            "80/80 [==============================] - 0s 397us/step - loss: 0.0607 - acc: 0.0000e+00 - val_loss: 0.0675 - val_acc: 0.0500\n",
            "Epoch 268/400\n",
            "80/80 [==============================] - 0s 417us/step - loss: 0.0604 - acc: 0.0000e+00 - val_loss: 0.0671 - val_acc: 0.0500\n",
            "Epoch 269/400\n",
            "80/80 [==============================] - 0s 363us/step - loss: 0.0600 - acc: 0.0000e+00 - val_loss: 0.0667 - val_acc: 0.0500\n",
            "Epoch 270/400\n",
            "80/80 [==============================] - 0s 368us/step - loss: 0.0595 - acc: 0.0000e+00 - val_loss: 0.0666 - val_acc: 0.0500\n",
            "Epoch 271/400\n",
            "80/80 [==============================] - 0s 393us/step - loss: 0.0592 - acc: 0.0000e+00 - val_loss: 0.0667 - val_acc: 0.0500\n",
            "Epoch 272/400\n",
            "80/80 [==============================] - 0s 492us/step - loss: 0.0587 - acc: 0.0000e+00 - val_loss: 0.0664 - val_acc: 0.0500\n",
            "Epoch 273/400\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.0583 - acc: 0.0000e+00 - val_loss: 0.0663 - val_acc: 0.0500\n",
            "Epoch 274/400\n",
            "80/80 [==============================] - 0s 447us/step - loss: 0.0579 - acc: 0.0000e+00 - val_loss: 0.0662 - val_acc: 0.0500\n",
            "Epoch 275/400\n",
            "80/80 [==============================] - 0s 376us/step - loss: 0.0576 - acc: 0.0000e+00 - val_loss: 0.0657 - val_acc: 0.0500\n",
            "Epoch 276/400\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.0571 - acc: 0.0000e+00 - val_loss: 0.0648 - val_acc: 0.0500\n",
            "Epoch 277/400\n",
            "80/80 [==============================] - 0s 466us/step - loss: 0.0567 - acc: 0.0000e+00 - val_loss: 0.0639 - val_acc: 0.0500\n",
            "Epoch 278/400\n",
            "80/80 [==============================] - 0s 411us/step - loss: 0.0564 - acc: 0.0000e+00 - val_loss: 0.0634 - val_acc: 0.0500\n",
            "Epoch 279/400\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.0560 - acc: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.0500\n",
            "Epoch 280/400\n",
            "80/80 [==============================] - 0s 437us/step - loss: 0.0556 - acc: 0.0000e+00 - val_loss: 0.0630 - val_acc: 0.0500\n",
            "Epoch 281/400\n",
            "80/80 [==============================] - 0s 388us/step - loss: 0.0552 - acc: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.0500\n",
            "Epoch 282/400\n",
            "80/80 [==============================] - 0s 365us/step - loss: 0.0547 - acc: 0.0000e+00 - val_loss: 0.0633 - val_acc: 0.0500\n",
            "Epoch 283/400\n",
            "80/80 [==============================] - 0s 362us/step - loss: 0.0545 - acc: 0.0000e+00 - val_loss: 0.0633 - val_acc: 0.0500\n",
            "Epoch 284/400\n",
            "80/80 [==============================] - 0s 426us/step - loss: 0.0542 - acc: 0.0000e+00 - val_loss: 0.0628 - val_acc: 0.0500\n",
            "Epoch 285/400\n",
            "80/80 [==============================] - 0s 413us/step - loss: 0.0538 - acc: 0.0000e+00 - val_loss: 0.0622 - val_acc: 0.0500\n",
            "Epoch 286/400\n",
            "80/80 [==============================] - 0s 531us/step - loss: 0.0534 - acc: 0.0000e+00 - val_loss: 0.0619 - val_acc: 0.0500\n",
            "Epoch 287/400\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.0530 - acc: 0.0000e+00 - val_loss: 0.0615 - val_acc: 0.0500\n",
            "Epoch 288/400\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.0527 - acc: 0.0000e+00 - val_loss: 0.0610 - val_acc: 0.0500\n",
            "Epoch 289/400\n",
            "80/80 [==============================] - 0s 376us/step - loss: 0.0523 - acc: 0.0000e+00 - val_loss: 0.0608 - val_acc: 0.0500\n",
            "Epoch 290/400\n",
            "80/80 [==============================] - 0s 414us/step - loss: 0.0520 - acc: 0.0000e+00 - val_loss: 0.0606 - val_acc: 0.0500\n",
            "Epoch 291/400\n",
            "80/80 [==============================] - 0s 401us/step - loss: 0.0517 - acc: 0.0000e+00 - val_loss: 0.0604 - val_acc: 0.0500\n",
            "Epoch 292/400\n",
            "80/80 [==============================] - 0s 384us/step - loss: 0.0513 - acc: 0.0000e+00 - val_loss: 0.0600 - val_acc: 0.0500\n",
            "Epoch 293/400\n",
            "80/80 [==============================] - 0s 426us/step - loss: 0.0510 - acc: 0.0000e+00 - val_loss: 0.0599 - val_acc: 0.0500\n",
            "Epoch 294/400\n",
            "80/80 [==============================] - 0s 436us/step - loss: 0.0507 - acc: 0.0000e+00 - val_loss: 0.0598 - val_acc: 0.0500\n",
            "Epoch 295/400\n",
            "80/80 [==============================] - 0s 377us/step - loss: 0.0504 - acc: 0.0000e+00 - val_loss: 0.0593 - val_acc: 0.0500\n",
            "Epoch 296/400\n",
            "80/80 [==============================] - 0s 429us/step - loss: 0.0500 - acc: 0.0000e+00 - val_loss: 0.0589 - val_acc: 0.0500\n",
            "Epoch 297/400\n",
            "80/80 [==============================] - 0s 413us/step - loss: 0.0497 - acc: 0.0000e+00 - val_loss: 0.0584 - val_acc: 0.0500\n",
            "Epoch 298/400\n",
            "80/80 [==============================] - 0s 372us/step - loss: 0.0494 - acc: 0.0000e+00 - val_loss: 0.0579 - val_acc: 0.0500\n",
            "Epoch 299/400\n",
            "80/80 [==============================] - 0s 436us/step - loss: 0.0491 - acc: 0.0000e+00 - val_loss: 0.0575 - val_acc: 0.0500\n",
            "Epoch 300/400\n",
            "80/80 [==============================] - 0s 428us/step - loss: 0.0488 - acc: 0.0000e+00 - val_loss: 0.0572 - val_acc: 0.0500\n",
            "Epoch 301/400\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.0485 - acc: 0.0000e+00 - val_loss: 0.0571 - val_acc: 0.0500\n",
            "Epoch 302/400\n",
            "80/80 [==============================] - 0s 419us/step - loss: 0.0482 - acc: 0.0000e+00 - val_loss: 0.0573 - val_acc: 0.0500\n",
            "Epoch 303/400\n",
            "80/80 [==============================] - 0s 399us/step - loss: 0.0479 - acc: 0.0000e+00 - val_loss: 0.0570 - val_acc: 0.0500\n",
            "Epoch 304/400\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0476 - acc: 0.0000e+00 - val_loss: 0.0569 - val_acc: 0.0500\n",
            "Epoch 305/400\n",
            "80/80 [==============================] - 0s 367us/step - loss: 0.0474 - acc: 0.0000e+00 - val_loss: 0.0568 - val_acc: 0.0500\n",
            "Epoch 306/400\n",
            "80/80 [==============================] - 0s 482us/step - loss: 0.0471 - acc: 0.0000e+00 - val_loss: 0.0563 - val_acc: 0.0500\n",
            "Epoch 307/400\n",
            "80/80 [==============================] - 0s 412us/step - loss: 0.0469 - acc: 0.0000e+00 - val_loss: 0.0557 - val_acc: 0.0500\n",
            "Epoch 308/400\n",
            "80/80 [==============================] - 0s 446us/step - loss: 0.0467 - acc: 0.0000e+00 - val_loss: 0.0551 - val_acc: 0.0500\n",
            "Epoch 309/400\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.0463 - acc: 0.0000e+00 - val_loss: 0.0550 - val_acc: 0.0500\n",
            "Epoch 310/400\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.0460 - acc: 0.0000e+00 - val_loss: 0.0550 - val_acc: 0.0500\n",
            "Epoch 311/400\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.0458 - acc: 0.0000e+00 - val_loss: 0.0550 - val_acc: 0.0500\n",
            "Epoch 312/400\n",
            "80/80 [==============================] - 0s 437us/step - loss: 0.0456 - acc: 0.0000e+00 - val_loss: 0.0546 - val_acc: 0.0500\n",
            "Epoch 313/400\n",
            "80/80 [==============================] - 0s 442us/step - loss: 0.0453 - acc: 0.0000e+00 - val_loss: 0.0543 - val_acc: 0.0500\n",
            "Epoch 314/400\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.0450 - acc: 0.0000e+00 - val_loss: 0.0541 - val_acc: 0.0500\n",
            "Epoch 315/400\n",
            "80/80 [==============================] - 0s 470us/step - loss: 0.0448 - acc: 0.0000e+00 - val_loss: 0.0538 - val_acc: 0.0500\n",
            "Epoch 316/400\n",
            "80/80 [==============================] - 0s 385us/step - loss: 0.0446 - acc: 0.0000e+00 - val_loss: 0.0535 - val_acc: 0.0500\n",
            "Epoch 317/400\n",
            "80/80 [==============================] - 0s 375us/step - loss: 0.0445 - acc: 0.0000e+00 - val_loss: 0.0530 - val_acc: 0.0500\n",
            "Epoch 318/400\n",
            "80/80 [==============================] - 0s 422us/step - loss: 0.0441 - acc: 0.0000e+00 - val_loss: 0.0527 - val_acc: 0.0500\n",
            "Epoch 319/400\n",
            "80/80 [==============================] - 0s 393us/step - loss: 0.0439 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0500\n",
            "Epoch 320/400\n",
            "80/80 [==============================] - 0s 398us/step - loss: 0.0436 - acc: 0.0000e+00 - val_loss: 0.0520 - val_acc: 0.0500\n",
            "Epoch 321/400\n",
            "80/80 [==============================] - 0s 353us/step - loss: 0.0434 - acc: 0.0000e+00 - val_loss: 0.0518 - val_acc: 0.0500\n",
            "Epoch 322/400\n",
            "80/80 [==============================] - 0s 397us/step - loss: 0.0432 - acc: 0.0000e+00 - val_loss: 0.0515 - val_acc: 0.0500\n",
            "Epoch 323/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.0429 - acc: 0.0000e+00 - val_loss: 0.0512 - val_acc: 0.0500\n",
            "Epoch 324/400\n",
            "80/80 [==============================] - 0s 496us/step - loss: 0.0428 - acc: 0.0000e+00 - val_loss: 0.0508 - val_acc: 0.0500\n",
            "Epoch 325/400\n",
            "80/80 [==============================] - 0s 371us/step - loss: 0.0426 - acc: 0.0000e+00 - val_loss: 0.0505 - val_acc: 0.0500\n",
            "Epoch 326/400\n",
            "80/80 [==============================] - 0s 378us/step - loss: 0.0423 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0500\n",
            "Epoch 327/400\n",
            "80/80 [==============================] - 0s 373us/step - loss: 0.0421 - acc: 0.0000e+00 - val_loss: 0.0508 - val_acc: 0.0500\n",
            "Epoch 328/400\n",
            "80/80 [==============================] - 0s 408us/step - loss: 0.0420 - acc: 0.0000e+00 - val_loss: 0.0508 - val_acc: 0.0500\n",
            "Epoch 329/400\n",
            "80/80 [==============================] - 0s 417us/step - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.0505 - val_acc: 0.0500\n",
            "Epoch 330/400\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.0415 - acc: 0.0000e+00 - val_loss: 0.0500 - val_acc: 0.0500\n",
            "Epoch 331/400\n",
            "80/80 [==============================] - 0s 396us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0494 - val_acc: 0.0500\n",
            "Epoch 332/400\n",
            "80/80 [==============================] - 0s 414us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0487 - val_acc: 0.0500\n",
            "Epoch 333/400\n",
            "80/80 [==============================] - 0s 429us/step - loss: 0.0410 - acc: 0.0000e+00 - val_loss: 0.0486 - val_acc: 0.0500\n",
            "Epoch 334/400\n",
            "80/80 [==============================] - 0s 473us/step - loss: 0.0407 - acc: 0.0000e+00 - val_loss: 0.0487 - val_acc: 0.0500\n",
            "Epoch 335/400\n",
            "80/80 [==============================] - 0s 416us/step - loss: 0.0405 - acc: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.0500\n",
            "Epoch 336/400\n",
            "80/80 [==============================] - 0s 442us/step - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.0500\n",
            "Epoch 337/400\n",
            "80/80 [==============================] - 0s 391us/step - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.0485 - val_acc: 0.0500\n",
            "Epoch 338/400\n",
            "80/80 [==============================] - 0s 374us/step - loss: 0.0401 - acc: 0.0000e+00 - val_loss: 0.0485 - val_acc: 0.0500\n",
            "Epoch 339/400\n",
            "80/80 [==============================] - 0s 407us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0478 - val_acc: 0.0500\n",
            "Epoch 340/400\n",
            "80/80 [==============================] - 0s 408us/step - loss: 0.0395 - acc: 0.0000e+00 - val_loss: 0.0472 - val_acc: 0.0500\n",
            "Epoch 341/400\n",
            "80/80 [==============================] - 0s 420us/step - loss: 0.0394 - acc: 0.0000e+00 - val_loss: 0.0466 - val_acc: 0.0500\n",
            "Epoch 342/400\n",
            "80/80 [==============================] - 0s 373us/step - loss: 0.0392 - acc: 0.0000e+00 - val_loss: 0.0463 - val_acc: 0.0500\n",
            "Epoch 343/400\n",
            "80/80 [==============================] - 0s 411us/step - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0500\n",
            "Epoch 344/400\n",
            "80/80 [==============================] - 0s 367us/step - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0500\n",
            "Epoch 345/400\n",
            "80/80 [==============================] - 0s 429us/step - loss: 0.0387 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0500\n",
            "Epoch 346/400\n",
            "80/80 [==============================] - 0s 436us/step - loss: 0.0386 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0500\n",
            "Epoch 347/400\n",
            "80/80 [==============================] - 0s 453us/step - loss: 0.0383 - acc: 0.0000e+00 - val_loss: 0.0458 - val_acc: 0.0500\n",
            "Epoch 348/400\n",
            "80/80 [==============================] - 0s 396us/step - loss: 0.0381 - acc: 0.0000e+00 - val_loss: 0.0457 - val_acc: 0.0500\n",
            "Epoch 349/400\n",
            "80/80 [==============================] - 0s 406us/step - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0455 - val_acc: 0.0500\n",
            "Epoch 350/400\n",
            "80/80 [==============================] - 0s 380us/step - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0452 - val_acc: 0.0500\n",
            "Epoch 351/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.0377 - acc: 0.0000e+00 - val_loss: 0.0449 - val_acc: 0.0500\n",
            "Epoch 352/400\n",
            "80/80 [==============================] - 0s 433us/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0447 - val_acc: 0.0500\n",
            "Epoch 353/400\n",
            "80/80 [==============================] - 0s 426us/step - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0447 - val_acc: 0.0500\n",
            "Epoch 354/400\n",
            "80/80 [==============================] - 0s 430us/step - loss: 0.0372 - acc: 0.0000e+00 - val_loss: 0.0444 - val_acc: 0.0500\n",
            "Epoch 355/400\n",
            "80/80 [==============================] - 0s 429us/step - loss: 0.0370 - acc: 0.0000e+00 - val_loss: 0.0441 - val_acc: 0.0500\n",
            "Epoch 356/400\n",
            "80/80 [==============================] - 0s 383us/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0439 - val_acc: 0.0500\n",
            "Epoch 357/400\n",
            "80/80 [==============================] - 0s 410us/step - loss: 0.0367 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0500\n",
            "Epoch 358/400\n",
            "80/80 [==============================] - 0s 401us/step - loss: 0.0366 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0500\n",
            "Epoch 359/400\n",
            "80/80 [==============================] - 0s 427us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0500\n",
            "Epoch 360/400\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.0363 - acc: 0.0000e+00 - val_loss: 0.0437 - val_acc: 0.0500\n",
            "Epoch 361/400\n",
            "80/80 [==============================] - 0s 369us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0433 - val_acc: 0.0500\n",
            "Epoch 362/400\n",
            "80/80 [==============================] - 0s 462us/step - loss: 0.0362 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0500\n",
            "Epoch 363/400\n",
            "80/80 [==============================] - 0s 397us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0429 - val_acc: 0.0500\n",
            "Epoch 364/400\n",
            "80/80 [==============================] - 0s 421us/step - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0500\n",
            "Epoch 365/400\n",
            "80/80 [==============================] - 0s 394us/step - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.0424 - val_acc: 0.0500\n",
            "Epoch 366/400\n",
            "80/80 [==============================] - 0s 386us/step - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.0423 - val_acc: 0.0500\n",
            "Epoch 367/400\n",
            "80/80 [==============================] - 0s 365us/step - loss: 0.0353 - acc: 0.0000e+00 - val_loss: 0.0421 - val_acc: 0.0500\n",
            "Epoch 368/400\n",
            "80/80 [==============================] - 0s 449us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0418 - val_acc: 0.0500\n",
            "Epoch 369/400\n",
            "80/80 [==============================] - 0s 402us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0414 - val_acc: 0.0500\n",
            "Epoch 370/400\n",
            "80/80 [==============================] - 0s 452us/step - loss: 0.0349 - acc: 0.0000e+00 - val_loss: 0.0412 - val_acc: 0.0500\n",
            "Epoch 371/400\n",
            "80/80 [==============================] - 0s 376us/step - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0411 - val_acc: 0.0500\n",
            "Epoch 372/400\n",
            "80/80 [==============================] - 0s 388us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0410 - val_acc: 0.0500\n",
            "Epoch 373/400\n",
            "80/80 [==============================] - 0s 376us/step - loss: 0.0345 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0500\n",
            "Epoch 374/400\n",
            "80/80 [==============================] - 0s 413us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0500\n",
            "Epoch 375/400\n",
            "80/80 [==============================] - 0s 423us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0500\n",
            "Epoch 376/400\n",
            "80/80 [==============================] - 0s 348us/step - loss: 0.0342 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0500\n",
            "Epoch 377/400\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.0500\n",
            "Epoch 378/400\n",
            "80/80 [==============================] - 0s 429us/step - loss: 0.0339 - acc: 0.0000e+00 - val_loss: 0.0398 - val_acc: 0.0500\n",
            "Epoch 379/400\n",
            "80/80 [==============================] - 0s 408us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0395 - val_acc: 0.0500\n",
            "Epoch 380/400\n",
            "80/80 [==============================] - 0s 367us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0396 - val_acc: 0.0500\n",
            "Epoch 381/400\n",
            "80/80 [==============================] - 0s 332us/step - loss: 0.0335 - acc: 0.0000e+00 - val_loss: 0.0400 - val_acc: 0.0500\n",
            "Epoch 382/400\n",
            "80/80 [==============================] - 0s 344us/step - loss: 0.0335 - acc: 0.0000e+00 - val_loss: 0.0400 - val_acc: 0.0500\n",
            "Epoch 383/400\n",
            "80/80 [==============================] - 0s 368us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0500\n",
            "Epoch 384/400\n",
            "80/80 [==============================] - 0s 386us/step - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0393 - val_acc: 0.0500\n",
            "Epoch 385/400\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0331 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0500\n",
            "Epoch 386/400\n",
            "80/80 [==============================] - 0s 394us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0385 - val_acc: 0.0500\n",
            "Epoch 387/400\n",
            "80/80 [==============================] - 0s 349us/step - loss: 0.0329 - acc: 0.0000e+00 - val_loss: 0.0382 - val_acc: 0.0500\n",
            "Epoch 388/400\n",
            "80/80 [==============================] - 0s 388us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0500\n",
            "Epoch 389/400\n",
            "80/80 [==============================] - 0s 359us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0500\n",
            "Epoch 390/400\n",
            "80/80 [==============================] - 0s 347us/step - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0500\n",
            "Epoch 391/400\n",
            "80/80 [==============================] - 0s 345us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0500\n",
            "Epoch 392/400\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0323 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0500\n",
            "Epoch 393/400\n",
            "80/80 [==============================] - 0s 352us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.0500\n",
            "Epoch 394/400\n",
            "80/80 [==============================] - 0s 366us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0500\n",
            "Epoch 395/400\n",
            "80/80 [==============================] - 0s 391us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0500\n",
            "Epoch 396/400\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0500\n",
            "Epoch 397/400\n",
            "80/80 [==============================] - 0s 356us/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0500\n",
            "Epoch 398/400\n",
            "80/80 [==============================] - 0s 338us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0500\n",
            "Epoch 399/400\n",
            "80/80 [==============================] - 0s 337us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0500\n",
            "Epoch 400/400\n",
            "80/80 [==============================] - 0s 351us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LZTM_XOEzfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKZQ2mOZDLt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(LSTM((1) , batch_input_shape=(None , 5 , 1) ,return_sequences =True))\n",
        "model.add(LSTM((1) ,return_sequences =False))\n",
        "model.compile(loss='mean_absolute_error' , optimizer = 'adam',metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0oqTXWpFU4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "90905c62-b60b-4981-eefe-e3bcfaf93b5a"
      },
      "source": [
        "plt.scatter(range(20) , results , c= 'r')\n",
        "plt.scatter(range(20),y_test , c= 'g')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fcebd6c5710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhAJfRCQQ/w+x2gQhfW5cbAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJKj0Z0rFcKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "e2aeb19f-40f8-4d6d-c2ad-5f3e964e511a"
      },
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcebd61f9b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hZkhYwMFuqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}